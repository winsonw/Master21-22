{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for image classification\n",
    "\n",
    "Use PyTorch to build and train a multilayer CNN to perform image classification on the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# replace with your own root directory\n",
    "ROOT=\"C:/Users/scsdch/OneDrive - University of Leeds/Teaching/Artificial Intelligence/workspace/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the dataset and produce iterable data loaders of minibatches. Give names to the classes.\n",
    "Randomly transform the data, producing unique images in each mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnsfrm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ColorJitter(hue=0.2, saturation=0.2, brightness=0.2),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1,0.1), scale=(0.9,1.1)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root=ROOT+'./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=trnsfrm\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root=ROOT+'./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=24, # Forward pass only so batch size can be larger\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timshow(x):\n",
    "    xa = np.transpose(x.numpy(),(1,2,0))\n",
    "    plt.imshow(xa)\n",
    "    plt.show()\n",
    "    \n",
    "# get some random training images using the data loader\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images and labels\n",
    "timshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "print(f\"labels {[classes[labels[i]] for i in range(10)]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of loss and accuracy for given dataset loader and model. This will be used for computing loss and accuracy on the test set after each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(loader, net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    n = 0    # counter for number of minibatches\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)      \n",
    "            \n",
    "            # accumulate loss\n",
    "            running_loss += loss_fn(outputs, labels)\n",
    "            n += 1\n",
    "            \n",
    "            # accumulate data for accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)    # add in the number of labels in this minibatch\n",
    "            correct += (predicted == labels).sum().item()  # add in the number of correct labels\n",
    "            \n",
    "    return running_loss/n, correct/total "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 5, 5])\n",
      "torch.Size([8])\n",
      "torch.Size([16, 8, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([64, 400])\n",
      "torch.Size([64])\n",
      "torch.Size([10, 64])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3,out_channels=8, kernel_size=5),    # no padding, stride=1, dilation=1 by default\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(in_channels=8,out_channels=16, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2z, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16*5*5,64),     # with 32x32 input, the feature map size reduces to 5x5 with 16 channels.\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,10)\n",
    ")\n",
    "\n",
    "for param in net.parameters():\n",
    "    print(param.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 50\n",
    "results_path = ROOT+'results/cnnclassifier50epochs.pt'\n",
    "statsrec = np.zeros((4,nepochs))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(nepochs):  # loop over the dataset multiple times\n",
    "    correct = 0          # number of examples predicted correctly (for accuracy)\n",
    "    total = 0            # number of examples\n",
    "    running_loss = 0.0   # accumulated loss (for mean loss)\n",
    "    n = 0                # number of minibatches\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        \n",
    "         # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward, backward, and update parameters\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        n += 1\n",
    "        \n",
    "        # accumulate data for accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)    # add in the number of labels in this minibatch\n",
    "        correct += (predicted == labels).sum().item()  # add in the number of correct labels\n",
    "    \n",
    "    # collect together statistics for this epoch\n",
    "    ltrn = running_loss/n\n",
    "    atrn = correct/total \n",
    "    ltst, atst = stats(test_loader, net)\n",
    "    statsrec[:,epoch] = (ltrn, atrn, ltst, atst)\n",
    "    print(f\"epoch: {epoch} training loss: {ltrn: .3f} training accuracy: {atrn: .1%}  test loss: {ltst: .3f} test accuracy: {atst: .1%}\")\n",
    "\n",
    "# save network parameters, losses and accuracy\n",
    "torch.save({\"state_dict\": net.state_dict(), \"stats\": statsrec}, results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss and accuracy on training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_path = ROOT+'results/cnnclassifier50epochs.pt'\n",
    "data = torch.load(results_path)\n",
    "statsrec = data[\"stats\"]\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.plot(statsrec[0], 'r', label = 'training loss', )\n",
    "plt.plot(statsrec[2], 'g', label = 'test loss' )\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training and test loss, and test accuracy')\n",
    "ax2=ax1.twinx()\n",
    "ax2.plot(statsrec[1], 'm', label = 'training accuracy')\n",
    "ax2.plot(statsrec[3], 'b', label = 'test accuracy')\n",
    "ax2.set_ylabel('accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "fig.savefig(\"roc.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
